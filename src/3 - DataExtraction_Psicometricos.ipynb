{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURACIÓN E IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar la raíz del proyecto al path\n",
    "ROOT = Path().resolve().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# Importar configuración centralizada\n",
    "from config import PATHS, CONFIG\n",
    "\n",
    "# ============= CONFIGURACIÓN USANDO CONFIG.PY =============\n",
    "\n",
    "# Usar rutas centralizadas\n",
    "ARCHIVO_EXCEL = PATHS.RAW / \"Formulario.xlsx\"\n",
    "CARPETA_SALIDA = PATHS.FEATURES\n",
    "\n",
    "print(f\"\\n Configuración:\")\n",
    "print(f\"  - Archivo Excel: {ARCHIVO_EXCEL}\")\n",
    "print(f\"  - Carpeta salida: {CARPETA_SALIDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daaa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_formulario_psicometrico():\n",
    "    \"\"\"\n",
    "    Procesa formulario con escalas UCLA y DASS-21\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"PROCESAMIENTO DE DATOS PSICOMÉTRICOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Crear carpeta de salida\n",
    "    if not os.path.exists(CARPETA_SALIDA):\n",
    "        os.makedirs(CARPETA_SALIDA)\n",
    "        print(f\"✓ Carpeta '{CARPETA_SALIDA}/' creada\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 1. CARGAR ARCHIVO EXCEL\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CARGANDO FORMULARIO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if not os.path.exists(ARCHIVO_EXCEL):\n",
    "        print(f\"Error: No se encuentra el archivo '{ARCHIVO_EXCEL}'\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(ARCHIVO_EXCEL)\n",
    "        print(f\"✓ Archivo cargado: {len(df)} respuestas\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer archivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nColumnas encontradas ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i}. {col}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 2. IDENTIFICAR Y RENOMBRAR COLUMNAS\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"IDENTIFICANDO COLUMNAS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Mapeo de nombres de columnas (basado en la imagen)\n",
    "    renombrar = {}\n",
    "    \n",
    "    # Buscar columnas demográficas\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'marca temporal' in col_lower or 'timestamp' in col_lower:\n",
    "            renombrar[col] = 'timestamp'\n",
    "        elif 'seudonimo' in col_lower or 'seudónimo' in col_lower:\n",
    "            renombrar[col] = 'id_participante'\n",
    "        elif 'edad' in col_lower:\n",
    "            renombrar[col] = 'edad'\n",
    "        elif 'género' in col_lower or 'genero' in col_lower:\n",
    "            renombrar[col] = 'genero'\n",
    "        elif 'año académico' in col_lower or 'ano academico' in col_lower:\n",
    "            renombrar[col] = 'ano_academico'\n",
    "        elif 'actividades extracurriculares' in col_lower:\n",
    "            renombrar[col] = 'actividades_extra'\n",
    "        elif 'miembro activo' in col_lower and 'whatsapp' in col_lower:\n",
    "            renombrar[col] = 'miembro_wa'\n",
    "    \n",
    "    df = df.rename(columns=renombrar)\n",
    "    print(f\"✓ {len(renombrar)} columnas demográficas identificadas\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 3. IDENTIFICAR COLUMNAS UCLA\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PROCESANDO ESCALA UCLA (SOLEDAD)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Buscar columnas UCLA - identificar por palabras clave en el texto\n",
    "    columnas_ucla = []\n",
    "    palabras_clave_ucla = [\n",
    "        'sintonía', 'compañía', 'recurrir', 'solo', 'grupo de amigos',\n",
    "        'en común', 'relación cercana', 'intereses', 'extrovertido',\n",
    "        'cercano', 'excluido', 'significativas', 'conoce', 'aislado',\n",
    "        'encontrar compañía', 'entienden', 'tímido', 'a tu alrededor',\n",
    "        'puedes hablar', 'puedes recurrir'\n",
    "    ]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        # Verificar si la columna contiene palabras clave de UCLA\n",
    "        if any(palabra in col_lower for palabra in palabras_clave_ucla):\n",
    "            columnas_ucla.append(col)\n",
    "    \n",
    "    # Si no funcionó, usar método alternativo: las primeras 20 preguntas numeradas\n",
    "    if len(columnas_ucla) != 20:\n",
    "        columnas_ucla = []\n",
    "        contador = 0\n",
    "        for i, col in enumerate(df.columns):\n",
    "            # Buscar columnas que empiezan con \"número.\" después de las demográficas\n",
    "            if any(col.strip().startswith(f\"{num}. \") for num in range(1, 21)):\n",
    "                columnas_ucla.append(col)\n",
    "                contador += 1\n",
    "                if contador == 20:\n",
    "                    break\n",
    "    \n",
    "    print(f\"✓ {len(columnas_ucla)} ítems UCLA identificados\")\n",
    "    \n",
    "    if len(columnas_ucla) != 20:\n",
    "        print(f\"Advertencia: Se esperaban 20 ítems UCLA, se encontraron {len(columnas_ucla)}\")\n",
    "        print(f\"    Primeras columnas identificadas:\")\n",
    "        for i, col in enumerate(columnas_ucla[:5], 1):\n",
    "            print(f\"      {i}. {col[:80]}...\")\n",
    "    \n",
    "    # Mapeo de respuestas UCLA\n",
    "    # Primero, verificar qué respuestas únicas hay\n",
    "    respuestas_unicas = set()\n",
    "    for col in columnas_ucla:\n",
    "        respuestas_unicas.update(df[col].dropna().unique())\n",
    "    \n",
    "    print(f\"\\nRespuestas únicas encontradas en UCLA:\")\n",
    "    for resp in sorted(respuestas_unicas, key=lambda x: str(x)):\n",
    "        print(f\"  - '{resp}'\")\n",
    "    \n",
    "    # Las respuestas ya vienen como números en string, solo convertir\n",
    "    mapeo_ucla = {\n",
    "        '1': 1, 1: 1,\n",
    "        '2': 2, 2: 2,\n",
    "        '3': 3, 3: 3,\n",
    "        '4': 4, 4: 4,\n",
    "        # Por si acaso vienen como texto\n",
    "        'Nunca': 1,\n",
    "        'Rara vez': 2,\n",
    "        'Raramente': 2,\n",
    "        'A veces': 3,\n",
    "        'Algunas veces': 3,\n",
    "        'Siempre': 4,\n",
    "        'A menudo': 4,\n",
    "        'Casi nunca': 1,\n",
    "        'Casi siempre': 4,\n",
    "        'Frecuentemente': 4,\n",
    "        'Ocasionalmente': 3\n",
    "    }\n",
    "    \n",
    "    # Aplicar mapeo a columnas UCLA\n",
    "    valores_no_mapeados = 0\n",
    "    for col in columnas_ucla:\n",
    "        df[col] = df[col].map(mapeo_ucla)\n",
    "        no_mapeados = df[col].isna().sum()\n",
    "        if no_mapeados > 0:\n",
    "            valores_no_mapeados += no_mapeados\n",
    "    \n",
    "    if valores_no_mapeados > 0:\n",
    "        print(f\"Total de valores no mapeados en UCLA: {valores_no_mapeados}\")\n",
    "    else:\n",
    "        print(f\"✓ Todas las respuestas UCLA mapeadas correctamente\")\n",
    "    \n",
    "    # Calcular puntuación total UCLA\n",
    "    df['ucla_total'] = df[columnas_ucla].sum(axis=1)\n",
    "    \n",
    "    print(f\"\\nEstadísticas UCLA:\")\n",
    "    print(f\"  Media: {df['ucla_total'].mean():.2f}\")\n",
    "    print(f\"  Mediana: {df['ucla_total'].median():.2f}\")\n",
    "    print(f\"  Mínimo: {df['ucla_total'].min():.0f}\")\n",
    "    print(f\"  Máximo: {df['ucla_total'].max():.0f}\")\n",
    "    print(f\"  Desviación estándar: {df['ucla_total'].std():.2f}\")\n",
    "    \n",
    "    # Clasificación de soledad (basada en literatura)\n",
    "    def clasificar_ucla(score):\n",
    "        if pd.isna(score):\n",
    "            return 'Sin datos'\n",
    "        elif score <= 28:\n",
    "            return 'Baja soledad'\n",
    "        elif score <= 43:\n",
    "            return 'Soledad moderada'\n",
    "        else:\n",
    "            return 'Alta soledad'\n",
    "    \n",
    "    df['ucla_categoria'] = df['ucla_total'].apply(clasificar_ucla)\n",
    "    \n",
    "    print(f\"\\nDistribución de soledad:\")\n",
    "    print(df['ucla_categoria'].value_counts().to_string())\n",
    "    \n",
    "    # ========================================\n",
    "    # 4. IDENTIFICAR COLUMNAS DASS-21\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"PROCESANDO ESCALA DASS-21\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Buscar columnas DASS-21 - identificar por palabras clave\n",
    "    columnas_dass = []\n",
    "    palabras_clave_dass = [\n",
    "        'tensión', 'boca seca', 'emoción positiva', 'dificultades para respirar',\n",
    "        'iniciativa', 'reaccionar exageradamente', 'temblores', 'gastando energía',\n",
    "        'presa del pánico', 'ilusionara', 'agitado', 'relajarme', 'desanimado',\n",
    "        'tolerado', 'borde del pánico', 'entusiasmarme', 'no valía',\n",
    "        'enfadado', 'corazón', 'asustado', 'vida no tenía sentido'\n",
    "    ]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        # Verificar si la columna contiene palabras clave de DASS\n",
    "        if any(palabra in col_lower for palabra in palabras_clave_dass):\n",
    "            columnas_dass.append(col)\n",
    "    \n",
    "    # Si no funcionó, buscar después de las UCLA\n",
    "    if len(columnas_dass) != 21:\n",
    "        columnas_dass = []\n",
    "        # Saltar las primeras 7 columnas (demográficas) y las 20 de UCLA\n",
    "        inicio_dass = 7 + 20\n",
    "        for i, col in enumerate(df.columns):\n",
    "            if i >= inicio_dass:\n",
    "                # Buscar columnas que empiezan con \"número.\"\n",
    "                if any(col.strip().startswith(f\"{num}. \") for num in range(1, 22)):\n",
    "                    columnas_dass.append(col)\n",
    "                    if len(columnas_dass) == 21:\n",
    "                        break\n",
    "    \n",
    "    print(f\"✓ {len(columnas_dass)} ítems DASS-21 identificados\")\n",
    "    \n",
    "    if len(columnas_dass) != 21:\n",
    "        print(f\"Advertencia: Se esperaban 21 ítems DASS, se encontraron {len(columnas_dass)}\")\n",
    "        print(f\"    Primeras columnas identificadas:\")\n",
    "        for i, col in enumerate(columnas_dass[:5], 1):\n",
    "            print(f\"      {i}. {col[:80]}...\")\n",
    "    \n",
    "    # Mapeo de respuestas DASS-21\n",
    "    # Primero, verificar qué respuestas únicas hay\n",
    "    respuestas_unicas_dass = set()\n",
    "    for col in columnas_dass:\n",
    "        respuestas_unicas_dass.update(df[col].dropna().unique())\n",
    "    \n",
    "    print(f\"\\nRespuestas únicas encontradas en DASS-21:\")\n",
    "    for resp in sorted(respuestas_unicas_dass, key=lambda x: str(x)):\n",
    "        print(f\"  - '{resp}'\")\n",
    "    \n",
    "    # Las respuestas ya vienen como números en string, solo convertir\n",
    "    mapeo_dass = {\n",
    "        '0': 0, 0: 0,\n",
    "        '1': 1, 1: 1,\n",
    "        '2': 2, 2: 2,\n",
    "        '3': 3, 3: 3,\n",
    "        # Por si acaso vienen como texto\n",
    "        'No me aplicó en absoluto': 0,\n",
    "        'Me aplicó un poco, o durante parte del tiempo': 1,\n",
    "        'Me aplicó bastante, o durante una buena parte del tiempo': 2,\n",
    "        'Me aplicó mucho, o la mayor parte del tiempo': 3,\n",
    "        'Nunca': 0,\n",
    "        'A veces': 1,\n",
    "        'A menudo': 2,\n",
    "        'Casi siempre': 3,\n",
    "        'Nada': 0,\n",
    "        'Un poco': 1,\n",
    "        'Bastante': 2,\n",
    "        'Mucho': 3,\n",
    "        'No': 0,\n",
    "        'Sí, un poco': 1,\n",
    "        'Sí, bastante': 2,\n",
    "        'Sí, mucho': 3\n",
    "    }\n",
    "    \n",
    "    # Aplicar mapeo a columnas DASS\n",
    "    valores_no_mapeados_dass = 0\n",
    "    for col in columnas_dass:\n",
    "        df[col] = df[col].map(mapeo_dass)\n",
    "        no_mapeados = df[col].isna().sum()\n",
    "        if no_mapeados > 0:\n",
    "            valores_no_mapeados_dass += no_mapeados\n",
    "    \n",
    "    if valores_no_mapeados_dass > 0:\n",
    "        print(f\"Total de valores no mapeados en DASS-21: {valores_no_mapeados_dass}\")\n",
    "    else:\n",
    "        print(f\"✓ Todas las respuestas DASS-21 mapeadas correctamente\")\n",
    "    \n",
    "    # DASS-21 tiene 3 subescalas (7 ítems cada una)\n",
    "    # Los ítems se distribuyen así:\n",
    "    # Depresión: 3, 5, 10, 13, 16, 17, 21 (posiciones en el cuestionario completo)\n",
    "    # Ansiedad: 2, 4, 7, 9, 15, 19, 20\n",
    "    # Estrés: 1, 6, 8, 11, 12, 14, 18\n",
    "    \n",
    "    if len(columnas_dass) == 21:\n",
    "        # Índices 0-based para las columnas\n",
    "        items_depresion = [2, 4, 9, 12, 15, 16, 20]  # Posiciones en el array\n",
    "        items_ansiedad = [1, 3, 6, 8, 14, 18, 19]\n",
    "        items_estres = [0, 5, 7, 10, 11, 13, 17]\n",
    "        \n",
    "        # Extraer valores específicos\n",
    "        df['dass_depresion_raw'] = sum(df[columnas_dass[i]] for i in items_depresion)\n",
    "        df['dass_ansiedad_raw'] = sum(df[columnas_dass[i]] for i in items_ansiedad)\n",
    "        df['dass_estres_raw'] = sum(df[columnas_dass[i]] for i in items_estres)\n",
    "        \n",
    "        # Multiplicar por 2 para equiparar a DASS-42\n",
    "        df['dass_depresion'] = df['dass_depresion_raw'] * 2\n",
    "        df['dass_ansiedad'] = df['dass_ansiedad_raw'] * 2\n",
    "        df['dass_estres'] = df['dass_estres_raw'] * 2\n",
    "        \n",
    "        print(f\"\\nEstadísticas DASS-21:\")\n",
    "        print(f\"\\nDepresión:\")\n",
    "        print(f\"  Media: {df['dass_depresion'].mean():.2f}\")\n",
    "        print(f\"  Mediana: {df['dass_depresion'].median():.2f}\")\n",
    "        print(f\"  Rango: {df['dass_depresion'].min():.0f} - {df['dass_depresion'].max():.0f}\")\n",
    "        \n",
    "        print(f\"\\nAnsiedad:\")\n",
    "        print(f\"  Media: {df['dass_ansiedad'].mean():.2f}\")\n",
    "        print(f\"  Mediana: {df['dass_ansiedad'].median():.2f}\")\n",
    "        print(f\"  Rango: {df['dass_ansiedad'].min():.0f} - {df['dass_ansiedad'].max():.0f}\")\n",
    "        \n",
    "        print(f\"\\nEstrés:\")\n",
    "        print(f\"  Media: {df['dass_estres'].mean():.2f}\")\n",
    "        print(f\"  Mediana: {df['dass_estres'].median():.2f}\")\n",
    "        print(f\"  Rango: {df['dass_estres'].min():.0f} - {df['dass_estres'].max():.0f}\")\n",
    "        \n",
    "        # Clasificaciones DASS-21 (basadas en literatura)\n",
    "        def clasificar_depresion(score):\n",
    "            if pd.isna(score):\n",
    "                return 'Sin datos'\n",
    "            elif score <= 9:\n",
    "                return 'Normal'\n",
    "            elif score <= 13:\n",
    "                return 'Leve'\n",
    "            elif score <= 20:\n",
    "                return 'Moderada'\n",
    "            elif score <= 27:\n",
    "                return 'Severa'\n",
    "            else:\n",
    "                return 'Extremadamente severa'\n",
    "        \n",
    "        def clasificar_ansiedad(score):\n",
    "            if pd.isna(score):\n",
    "                return 'Sin datos'\n",
    "            elif score <= 7:\n",
    "                return 'Normal'\n",
    "            elif score <= 9:\n",
    "                return 'Leve'\n",
    "            elif score <= 14:\n",
    "                return 'Moderada'\n",
    "            elif score <= 19:\n",
    "                return 'Severa'\n",
    "            else:\n",
    "                return 'Extremadamente severa'\n",
    "        \n",
    "        def clasificar_estres(score):\n",
    "            if pd.isna(score):\n",
    "                return 'Sin datos'\n",
    "            elif score <= 14:\n",
    "                return 'Normal'\n",
    "            elif score <= 18:\n",
    "                return 'Leve'\n",
    "            elif score <= 25:\n",
    "                return 'Moderado'\n",
    "            elif score <= 33:\n",
    "                return 'Severo'\n",
    "            else:\n",
    "                return 'Extremadamente severo'\n",
    "        \n",
    "        df['dass_depresion_cat'] = df['dass_depresion'].apply(clasificar_depresion)\n",
    "        df['dass_ansiedad_cat'] = df['dass_ansiedad'].apply(clasificar_ansiedad)\n",
    "        df['dass_estres_cat'] = df['dass_estres'].apply(clasificar_estres)\n",
    "        \n",
    "        print(f\"\\nDistribución de depresión:\")\n",
    "        print(df['dass_depresion_cat'].value_counts().to_string())\n",
    "        \n",
    "        print(f\"\\nDistribución de ansiedad:\")\n",
    "        print(df['dass_ansiedad_cat'].value_counts().to_string())\n",
    "        \n",
    "        print(f\"\\nDistribución de estrés:\")\n",
    "        print(df['dass_estres_cat'].value_counts().to_string())\n",
    "    \n",
    "    # ========================================\n",
    "    # 5. FILTRAR PARTICIPANTES EXCLUIDOS\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"APLICANDO CRITERIOS DE EXCLUSIÓN\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Participantes a excluir (< 10 publicaciones o datos incompletos)\n",
    "    PARTICIPANTES_EXCLUIDOS = ['EST005', 'EST006', 'EST022']\n",
    "    \n",
    "    n_antes = len(df)\n",
    "    df = df[~df['id_participante'].isin(PARTICIPANTES_EXCLUIDOS)]\n",
    "    n_excluidos = n_antes - len(df)\n",
    "    \n",
    "    if n_excluidos > 0:\n",
    "        print(f\"✓ Excluidos {n_excluidos} participantes:\")\n",
    "        for pid in PARTICIPANTES_EXCLUIDOS:\n",
    "            if pid in df[~df['id_participante'].isin(PARTICIPANTES_EXCLUIDOS)].index:\n",
    "                continue\n",
    "            print(f\"  - {pid} (< 10 publicaciones o datos incompletos)\")\n",
    "    \n",
    "    print(f\"\\nMuestra final: n={len(df)} participantes\")\n",
    "    \n",
    "    # ========================================\n",
    "    # 6. CREAR DATASET LIMPIO\n",
    "    # ========================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GENERANDO ARCHIVOS DE SALIDA\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Seleccionar columnas relevantes\n",
    "    columnas_salida = ['id_participante']\n",
    "    \n",
    "    # Agregar demográficas si existen\n",
    "    for col in ['timestamp', 'edad', 'genero', 'ano_academico', 'actividades_extra', 'miembro_wa']:\n",
    "        if col in df.columns:\n",
    "            columnas_salida.append(col)\n",
    "    \n",
    "    # Agregar puntuaciones psicométricas\n",
    "    columnas_salida.extend([\n",
    "        'ucla_total', 'ucla_categoria',\n",
    "        'dass_depresion', 'dass_ansiedad', 'dass_estres',\n",
    "        'dass_depresion_cat', 'dass_ansiedad_cat', 'dass_estres_cat'\n",
    "    ])\n",
    "    \n",
    "    # Filtrar solo columnas que existen\n",
    "    columnas_salida = [col for col in columnas_salida if col in df.columns]\n",
    "    \n",
    "    df_psicometrico = df[columnas_salida].copy()\n",
    "    \n",
    "    # Ordenar por id_participante (numérico si es posible) antes de guardar\n",
    "    if 'id_participante' in df_psicometrico.columns:\n",
    "        try:\n",
    "            nums = df_psicometrico['id_participante'].astype(str).str.extract(r'(\\d+)$')[0]\n",
    "            if nums.notna().any():\n",
    "                df_psicometrico['_orden'] = nums.astype(float).astype('Int64')\n",
    "                df_psicometrico = df_psicometrico.sort_values(['_orden', 'id_participante']).drop(columns=['_orden'])\n",
    "            else:\n",
    "                df_psicometrico = df_psicometrico.sort_values('id_participante')\n",
    "        except Exception:\n",
    "            df_psicometrico = df_psicometrico.sort_values('id_participante')\n",
    "\n",
    "    # Guardar archivo principal\n",
    "    archivo_salida = os.path.join(CARPETA_SALIDA, 'datos_psicometricos.csv')\n",
    "    df_psicometrico.to_csv(archivo_salida, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n✓ {archivo_salida}\")\n",
    "    print(f\"  Total: {len(df_psicometrico)} participantes\")\n",
    "    print(f\"  Columnas: {len(df_psicometrico.columns)}\")\n",
    "    \n",
    "    # Guardar archivo con todos los detalles (incluyendo respuestas individuales)\n",
    "    archivo_completo = os.path.join(CARPETA_SALIDA, 'datos_psicometricos_completo.csv')\n",
    "\n",
    "    # Ordenar df completo por id_participante antes de guardar\n",
    "    if 'id_participante' in df.columns:\n",
    "        try:\n",
    "            nums_all = df['id_participante'].astype(str).str.extract(r'(\\d+)$')[0]\n",
    "            if nums_all.notna().any():\n",
    "                df['_orden'] = nums_all.astype(float).astype('Int64')\n",
    "                df = df.sort_values(['_orden', 'id_participante']).drop(columns=['_orden'])\n",
    "            else:\n",
    "                df = df.sort_values('id_participante')\n",
    "        except Exception:\n",
    "            df = df.sort_values('id_participante')\n",
    "\n",
    "    df.to_csv(archivo_completo, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n✓ {archivo_completo}\")\n",
    "    print(f\"  Incluye todas las respuestas individuales\")\n",
    "    \n",
    "    # Vista previa\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"VISTA PREVIA\")\n",
    "    print(f\"{'='*80}\")\n",
    "    cols_preview = ['id_participante', 'ucla_total', 'dass_depresion', 'dass_ansiedad', 'dass_estres']\n",
    "    cols_preview = [c for c in cols_preview if c in df_psicometrico.columns]\n",
    "    print(df_psicometrico[cols_preview].head().to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"✓ PROCESAMIENTO COMPLETADO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return df_psicometrico\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_resultado = procesar_formulario_psicometrico()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv-ipykernel)",
   "language": "python",
   "name": "venv-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
