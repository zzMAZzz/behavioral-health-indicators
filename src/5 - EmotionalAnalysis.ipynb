{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURACIÓN E IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Agregar la raíz del proyecto al path\n",
    "ROOT = Path().resolve().parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "# Importar configuración centralizada\n",
    "from config import PATHS, CONFIG\n",
    "\n",
    "print(\"✓ Configuración cargada correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d548e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar rutas centralizadas\n",
    "CARPETA_LIMPIA = PATHS.PROCESSED\n",
    "CARPETA_FEATURES = PATHS.FEATURES\n",
    "ARCHIVO_ENTRADA = PATHS.PUBLICACIONES_TEXTO\n",
    "\n",
    "# Usar configuración centralizada\n",
    "USAR_PYSENTIMIENTO = CONFIG.USAR_PYSENTIMIENTO\n",
    "USAR_EMOJIS = CONFIG.USAR_EMOJIS\n",
    "MOSTRAR_PROGRESO = CONFIG.MOSTRAR_PROGRESO\n",
    "PROGRESO_CADA = CONFIG.PROGRESO_CADA\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURACIÓN ACTIVA:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Archivo entrada: {ARCHIVO_ENTRADA}\")\n",
    "print(f\"Carpeta salida: {CARPETA_FEATURES}\")\n",
    "print(f\"Pysentimiento: {'Activo' if USAR_PYSENTIMIENTO else 'Inactivo'}\")\n",
    "print(f\"Análisis de emojis: {'Activo' if USAR_EMOJIS else 'Inactivo'}\")\n",
    "print(f\"Mostrar progreso cada {PROGRESO_CADA} registros\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fff470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_caracteristicas_linguisticas(texto):\n",
    "    \"\"\"Extrae características lingüísticas básicas del texto\"\"\"\n",
    "    \n",
    "    palabras = texto.split()\n",
    "    num_palabras = len(palabras)\n",
    "    num_caracteres = len(texto)\n",
    "    \n",
    "    # Longitud promedio de palabras\n",
    "    longitud_palabra_prom = np.mean([len(p) for p in palabras]) if num_palabras > 0 else 0\n",
    "    \n",
    "    # Contar signos de puntuación\n",
    "    num_signos_exclamacion = texto.count('!')\n",
    "    num_signos_pregunta = texto.count('?')\n",
    "    num_puntos = texto.count('.')\n",
    "    num_comas = texto.count(',')\n",
    "    \n",
    "    # Palabras únicas (riqueza léxica)\n",
    "    palabras_unicas = len(set(palabras)) if num_palabras > 0 else 0\n",
    "    riqueza_lexica = palabras_unicas / num_palabras if num_palabras > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'num_palabras': num_palabras,\n",
    "        'num_caracteres': num_caracteres,\n",
    "        'longitud_palabra_prom': round(longitud_palabra_prom, 2),\n",
    "        'num_signos_exclamacion': num_signos_exclamacion,\n",
    "        'num_signos_pregunta': num_signos_pregunta,\n",
    "        'num_puntos': num_puntos,\n",
    "        'num_comas': num_comas,\n",
    "        'palabras_unicas': palabras_unicas,\n",
    "        'riqueza_lexica': round(riqueza_lexica, 3)\n",
    "    }\n",
    "\n",
    "\n",
    "def extraer_pronombres(texto):\n",
    "    \"\"\"Extrae métricas de uso de pronombres\"\"\"\n",
    "    \n",
    "    texto_lower = ' ' + texto.lower() + ' '\n",
    "    num_palabras = len(texto.split())\n",
    "    \n",
    "    # Pronombres de primera persona singular\n",
    "    pronombres_1era_sing = ['yo', 'me', 'mi', 'mí', 'conmigo']\n",
    "    count_1era_sing = sum(texto_lower.count(f' {p} ') for p in pronombres_1era_sing)\n",
    "    \n",
    "    # Pronombres de primera persona plural\n",
    "    pronombres_1era_plur = ['nosotros', 'nosotras', 'nos', 'nuestro', 'nuestra']\n",
    "    count_1era_plur = sum(texto_lower.count(f' {p} ') for p in pronombres_1era_plur)\n",
    "    \n",
    "    # Pronombres de segunda persona\n",
    "    pronombres_2da = ['tú', 'tu', 'te', 'ti', 'contigo', 'usted', 'ustedes']\n",
    "    count_2da = sum(texto_lower.count(f' {p} ') for p in pronombres_2da)\n",
    "    \n",
    "    # Pronombres de tercera persona\n",
    "    pronombres_3era = ['él', 'ella', 'ellos', 'ellas', 'le', 'les', 'lo', 'la', 'los', 'las']\n",
    "    count_3era = sum(texto_lower.count(f' {p} ') for p in pronombres_3era)\n",
    "    \n",
    "    return {\n",
    "        'num_pronombres_1era_sing': count_1era_sing,\n",
    "        'num_pronombres_1era_plur': count_1era_plur,\n",
    "        'num_pronombres_2da': count_2da,\n",
    "        'num_pronombres_3era': count_3era,\n",
    "        'pct_pronombres_1era_sing': round((count_1era_sing / max(num_palabras, 1)) * 100, 2),\n",
    "        'pct_pronombres_1era_plur': round((count_1era_plur / max(num_palabras, 1)) * 100, 2),\n",
    "        'pct_pronombres_2da': round((count_2da / max(num_palabras, 1)) * 100, 2),\n",
    "        'pct_pronombres_3era': round((count_3era / max(num_palabras, 1)) * 100, 2)\n",
    "    }\n",
    "\n",
    "\n",
    "def extraer_palabras_clave(texto):\n",
    "    \"\"\"Extrae métricas de palabras clave indicadoras\"\"\"\n",
    "    \n",
    "    texto_lower = texto.lower()\n",
    "    num_palabras = len(texto.split())\n",
    "    \n",
    "    # Palabras absolutistas\n",
    "    absolutistas = ['siempre', 'nunca', 'todo', 'nada', 'todos', 'nadie', 'ninguno', 'jamás']\n",
    "    count_absolutistas = sum(texto_lower.count(p) for p in absolutistas)\n",
    "    \n",
    "    # Palabras negativas\n",
    "    negativas = ['no', 'ni', 'sin', 'nunca', 'nada', 'nadie']\n",
    "    count_negativas = sum(texto_lower.count(f' {p} ') for p in negativas)\n",
    "    \n",
    "    # Palabras de causalidad\n",
    "    causales = ['porque', 'causa', 'razón', 'debido', 'por eso', 'por lo tanto']\n",
    "    count_causales = sum(texto_lower.count(p) for p in causales)\n",
    "    \n",
    "    # Palabras tentativas/incertidumbre\n",
    "    tentativas = ['quizás', 'tal vez', 'posiblemente', 'probablemente', 'quizá', 'puede']\n",
    "    count_tentativas = sum(texto_lower.count(p) for p in tentativas)\n",
    "    \n",
    "    return {\n",
    "        'num_absolutistas': count_absolutistas,\n",
    "        'num_negativas': count_negativas,\n",
    "        'num_causales': count_causales,\n",
    "        'num_tentativas': count_tentativas,\n",
    "        'pct_absolutistas': round((count_absolutistas / max(num_palabras, 1)) * 100, 2),\n",
    "        'pct_negativas': round((count_negativas / max(num_palabras, 1)) * 100, 2),\n",
    "        'pct_causales': round((count_causales / max(num_palabras, 1)) * 100, 2),\n",
    "        'pct_tentativas': round((count_tentativas / max(num_palabras, 1)) * 100, 2)\n",
    "    }\n",
    "\n",
    "\n",
    "def extraer_emojis(texto_original):\n",
    "    \"\"\"Extrae métricas de emojis (requiere librería emoji)\"\"\"\n",
    "    \n",
    "    if not USAR_EMOJIS:\n",
    "        return {\n",
    "            'num_emojis': 0,\n",
    "            'emojis_por_palabra': 0\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        import emoji\n",
    "        num_emojis = emoji.emoji_count(texto_original)\n",
    "        num_palabras = len(texto_original.split())\n",
    "        \n",
    "        return {\n",
    "            'num_emojis': num_emojis,\n",
    "            'emojis_por_palabra': round(num_emojis / max(num_palabras, 1), 3)\n",
    "        }\n",
    "    except ImportError:\n",
    "        print(\"Librería 'emoji' no instalada. Instalar con: pip install emoji\")\n",
    "        return {\n",
    "            'num_emojis': 0,\n",
    "            'emojis_por_palabra': 0\n",
    "        }\n",
    "\n",
    "\n",
    "def extraer_sentimiento_emocion(texto):\n",
    "    \"\"\"Extrae análisis de sentimiento y emoción usando pysentimiento\"\"\"\n",
    "    \n",
    "    if not USAR_PYSENTIMIENTO:\n",
    "        return {\n",
    "            'sentimiento': None,\n",
    "            'score_pos': 0,\n",
    "            'score_neg': 0,\n",
    "            'score_neu': 0,\n",
    "            'emocion': None,\n",
    "            'score_alegria': 0,\n",
    "            'score_tristeza': 0,\n",
    "            'score_enojo': 0,\n",
    "            'score_miedo': 0,\n",
    "            'score_sorpresa': 0,\n",
    "            'score_disgusto': 0\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        from pysentimiento import create_analyzer\n",
    "        \n",
    "        # Crear analizadores (se cachean automáticamente)\n",
    "        if not hasattr(extraer_sentimiento_emocion, 'analyzer_sent'):\n",
    "            extraer_sentimiento_emocion.analyzer_sent = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "            extraer_sentimiento_emocion.analyzer_emo = create_analyzer(task=\"emotion\", lang=\"es\")\n",
    "        \n",
    "        # Análisis de sentimiento\n",
    "        sent = extraer_sentimiento_emocion.analyzer_sent.predict(texto)\n",
    "        \n",
    "        # Análisis de emoción\n",
    "        emo = extraer_sentimiento_emocion.analyzer_emo.predict(texto)\n",
    "        \n",
    "        return {\n",
    "            'sentimiento': sent.output,\n",
    "            'score_pos': round(sent.probas.get('POS', 0), 4),\n",
    "            'score_neg': round(sent.probas.get('NEG', 0), 4),\n",
    "            'score_neu': round(sent.probas.get('NEU', 0), 4),\n",
    "            'emocion': emo.output,\n",
    "            'score_alegria': round(emo.probas.get('joy', 0), 4),\n",
    "            'score_tristeza': round(emo.probas.get('sadness', 0), 4),\n",
    "            'score_enojo': round(emo.probas.get('anger', 0), 4),\n",
    "            'score_miedo': round(emo.probas.get('fear', 0), 4),\n",
    "            'score_sorpresa': round(emo.probas.get('surprise', 0), 4),\n",
    "            'score_disgusto': round(emo.probas.get('disgust', 0), 4)\n",
    "        }\n",
    "    except ImportError:\n",
    "        print(\"Librería 'pysentimiento' no instalada. Instalar con: pip install pysentimiento\")\n",
    "        return {\n",
    "            'sentimiento': None,\n",
    "            'score_pos': 0,\n",
    "            'score_neg': 0,\n",
    "            'score_neu': 0,\n",
    "            'emocion': None,\n",
    "            'score_alegria': 0,\n",
    "            'score_tristeza': 0,\n",
    "            'score_enojo': 0,\n",
    "            'score_miedo': 0,\n",
    "            'score_sorpresa': 0,\n",
    "            'score_disgusto': 0\n",
    "        }\n",
    "\n",
    "\n",
    "def extraer_todas_caracteristicas(df):\n",
    "    \"\"\"\n",
    "    Extrae TODAS las características de cada publicación\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con columnas 'texto_limpio' y 'texto_publicacion'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con todas las características extraídas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"EXTRACCIÓN DE CARACTERÍSTICAS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total de registros a procesar: {len(df)}\")\n",
    "    \n",
    "    if USAR_PYSENTIMIENTO:\n",
    "        print(\"✓ Análisis de sentimiento y emoción: ACTIVADO\")\n",
    "    else:\n",
    "        print(\"Análisis de sentimiento y emoción: DESACTIVADO\")\n",
    "    \n",
    "    if USAR_EMOJIS:\n",
    "        print(\"✓ Análisis de emojis: ACTIVADO\")\n",
    "    else:\n",
    "        print(\"Análisis de emojis: DESACTIVADO\")\n",
    "    \n",
    "    print(f\"\\nProcesando...\")\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        texto_limpio = row.get('texto_limpio', '')\n",
    "        texto_original = row.get('texto_publicacion', texto_limpio)\n",
    "        \n",
    "        # Extraer todas las características\n",
    "        caracteristicas = {\n",
    "            'id_participante': row.get('id_participante', ''),\n",
    "            'id_publicacion': row.get('id_publicacion', ''),\n",
    "            'fecha_publicacion': row.get('fecha_publicacion', '')\n",
    "        }\n",
    "        \n",
    "        # 1. Características lingüísticas\n",
    "        caracteristicas.update(extraer_caracteristicas_linguisticas(texto_limpio))\n",
    "        \n",
    "        # 2. Pronombres\n",
    "        caracteristicas.update(extraer_pronombres(texto_limpio))\n",
    "        \n",
    "        # 3. Palabras clave\n",
    "        caracteristicas.update(extraer_palabras_clave(texto_limpio))\n",
    "        \n",
    "        # 4. Emojis\n",
    "        caracteristicas.update(extraer_emojis(texto_original))\n",
    "        \n",
    "        # 5. Sentimiento y emoción\n",
    "        caracteristicas.update(extraer_sentimiento_emocion(texto_limpio))\n",
    "        \n",
    "        resultados.append(caracteristicas)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        if MOSTRAR_PROGRESO and (idx + 1) % PROGRESO_CADA == 0:\n",
    "            porcentaje = ((idx + 1) / len(df)) * 100\n",
    "            print(f\"  Procesadas {idx + 1}/{len(df)} publicaciones ({porcentaje:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n✓ Todas las publicaciones procesadas\")\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "\n",
    "def analizar_publicaciones():\n",
    "    \"\"\"Proceso completo de extracción de características\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ANÁLISIS DE CARACTERÍSTICAS DE PUBLICACIONES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Crear carpeta de features si no existe\n",
    "    if not os.path.exists(CARPETA_FEATURES):\n",
    "        os.makedirs(CARPETA_FEATURES)\n",
    "        print(f\"✓ Carpeta '{CARPETA_FEATURES}/' creada\")\n",
    "    \n",
    "    # Verificar archivo de entrada\n",
    "    ruta_entrada = os.path.join(CARPETA_LIMPIA, ARCHIVO_ENTRADA)\n",
    "    \n",
    "    if not os.path.exists(ruta_entrada):\n",
    "        print(f\"\\n Error: No se encuentra el archivo '{ruta_entrada}'\")\n",
    "        print(f\"   Asegúrate de ejecutar primero el preprocesamiento\")\n",
    "        return None\n",
    "    \n",
    "    # Leer datos\n",
    "    print(f\"\\nLeyendo archivo: {ruta_entrada}\")\n",
    "    try:\n",
    "        df = pd.read_csv(ruta_entrada, encoding='utf-8-sig')\n",
    "        print(f\"✓ {len(df)} registros cargados\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error leyendo archivo: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Verificar columnas necesarias\n",
    "    columnas_necesarias = ['texto_limpio']\n",
    "    if not all(col in df.columns for col in columnas_necesarias):\n",
    "        print(f\" Error: Falta la columna 'texto_limpio'\")\n",
    "        return None\n",
    "    \n",
    "    # Extraer características\n",
    "    df_caracteristicas = extraer_todas_caracteristicas(df)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    nombre_salida = f\"caracteristicas_completas.csv\"\n",
    "    ruta_salida = os.path.join(CARPETA_FEATURES, nombre_salida)\n",
    "    df_caracteristicas.to_csv(ruta_salida, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"✓ ANÁLISIS COMPLETADO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total de características extraídas: {len(df_caracteristicas.columns)} columnas\")\n",
    "    print(f\"Archivo guardado: {ruta_salida}\")\n",
    "    \n",
    "    # Mostrar estadísticas\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ESTADÍSTICAS DE CARACTERÍSTICAS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if 'sentimiento' in df_caracteristicas.columns and df_caracteristicas['sentimiento'].notna().any():\n",
    "        print(\"\\nDistribución de sentimientos:\")\n",
    "        print(df_caracteristicas['sentimiento'].value_counts())\n",
    "        \n",
    "        print(\"\\nDistribución de emociones:\")\n",
    "        print(df_caracteristicas['emocion'].value_counts())\n",
    "    \n",
    "    print(\"\\nPromedio de características lingüísticas:\")\n",
    "    cols_numericas = ['num_palabras', 'num_caracteres', 'longitud_palabra_prom', \n",
    "                      'riqueza_lexica', 'pct_pronombres_1era_sing']\n",
    "    for col in cols_numericas:\n",
    "        if col in df_caracteristicas.columns:\n",
    "            print(f\"  {col}: {df_caracteristicas[col].mean():.2f}\")\n",
    "    \n",
    "    return df_caracteristicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14469baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_resultado = analizar_publicaciones()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv-ipykernel)",
   "language": "python",
   "name": "venv-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
